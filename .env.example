# Helper Config
GITHUB_TOKEN=your_github_token_here

# LLM Configuration
# Backend options: llamacpp, ollama, openai
LLM__BACKEND=llamacpp

# LlamaCpp Settings
LLM__MODEL_PATH=/path/to/your/model.gguf
LLM__CONTEXT_SIZE=4096
LLM__GPU_LAYERS=32

# Ollama / OpenAI Settings
# LLM__MODEL_NAME=llama3
# LLM__BASE_URL=http://localhost:11434  # For Ollama
# LLM__BASE_URL=http://localhost:1234/v1  # For LM Studio (OpenAI compatible)

LLM__TEMPERATURE=0.7
LLM__API_KEY=optional_api_key

# Voice Configuration
VOICE__WAKE_WORD=jarvis
VOICE__PORCUPINE_ACCESS_KEY=your_porcupine_access_key
VOICE__STT_MODEL_SIZE=base
VOICE__TTS_VOICE=en_US-lessac-medium

# Email Configuration
EMAIL__USER=your_email@example.com
EMAIL__PASSWORD=your_email_password
EMAIL__SMTP_SERVER=smtp.gmail.com
EMAIL__SMTP_PORT=587

# System Configuration
SYSTEM__DEBUG=false
SYSTEM__MODELS_DIR=./models
SYSTEM__LOGS_DIR=./logs

# Safety
SAFETY__CONFIRM_DESTRUCTIVE_ACTIONS=true
